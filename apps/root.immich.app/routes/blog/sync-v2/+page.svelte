<script>
  import mediumTests from '$lib/assets/blog/medium-tests.webp';
  import { Posts } from '$lib/blog';
  import BlogPage from '$lib/components/BlogPage.svelte';
  import CodeBlock from '$lib/components/CodeBlock.svelte';
  import GithubReference from '$lib/components/GithubReference.svelte';
  import List from '$lib/components/List.svelte';
  import { Code, Heading, Link, Text } from '@immich/ui';
  import { dart, json } from 'svelte-highlight/languages';
</script>

<BlogPage post={Posts.NewSyncImplementation}>
  <Text>
    For some time now it has been painfully obvious to the team (and its users ðŸ˜‚), that the mobile app needs a new
    synchronization implementation. This is also one of the last roadblocks for a stable release. This post is a deep
    dive into the core issues of syncing large volumes of data with a mobile client, the technical details of the new
    implementation, as well as our thought process behind the decisions that led to the current design.
  </Text>

  <section class="flex flex-col gap-2">
    <Heading tag="h2" size="giant">Sync v1</Heading>
    <Text>
      To give a little bit of background on how the old implementation came to be, it's worth noting that the mobile app
      has changed a lot since it was originally built in 2022. Over time, a lot has changed, and, prior to recent
      discussions around <Code>v2</Code>, the team had never formally discussed a solution to the problem. Thus the
      current state, as you would expect, was problematic in a few crucial ways:
    </Text>
    <List>
      <li>
        <b>Compatibility</b> &mdash; since client applications can update independently of the server, it becomes too
        easy to introduce breaking changes, even when <i>adding</i>
        a new property.
      </li>
      <li>
        <b>Performance</b> &mdash; the <i>volume</i> of data often results in additional problems with memory usage, both
        on the server and the mobile device. Combined with the JSON message format, which requires the entire message to
        be in memory for serialization and deserialization, this leads to high memory usage during each synchronization attempt.
      </li>
      <li>
        <b>Efficiency</b> &mdash; a single change on the server could result in needing to re-send <i>a lot</i> of duplicate
        data to the mobile app again. Albums are especially problematic. The old implementation relies on re-sending all
        albums and their assets to the mobile app whenever the album page was "refreshed", which it did by default on navigation.
      </li>
    </List>
  </section>

  <Text>
    In short, the previous implementation has a lot of limitations which continue to plague users, especially those with
    large libraries (100,000+ assets). From the user's perspective, the app takes a long time to open, a long time to
    load the main timeline, results in a significant drop in FPS while the synchronization process is running, increases
    battery drain, and all while potentially not even being able to complete the sync at all.
  </Text>

  <section class="flex flex-col gap-2">
    <Heading tag="h2" size="giant">Sync v2</Heading>
    <Text>
      The high level goal was simple: fix all the issues with the previous implementation ðŸ˜‚. In all seriousness, we
      wanted the new implementation to have the following characteristics:
    </Text>
    <List>
      <li>
        <b>End-to-end streaming</b> &mdash; stream data from the server's database to the client's database in chunks
      </li>
      <li><b>Resumable</b> &mdash; easily resume a sync from where you left off</li>
      <li><b>Incremental</b> &mdash; only send data that has changed since the last sync</li>
      <li><b>Fast</b> &mdash; the queries that determine what has changed should not require full table scans</li>
      <li>
        <b>Efficient</b> &mdash; reduce memory usage by avoiding serializing or deserializing huge chunks of JSON in memory,
        especially on the main thread
      </li>
    </List>
  </section>

  <section class="flex flex-col gap-2">
    <Heading tag="h3" size="large">End-to-end streaming</Heading>
    <Text>
      Off the bat we realized that having end-to-end streaming would be a huge win in terms of memory, stability, and
      throughput. To support end-to-end streaming to the mobile app, we would need to:
    </Text>

    <List>
      <li>Read from PostgreSQL in chunks &mdash; Server</li>
      <li>Serialize in chunks &mdash; Server</li>
      <li>Write data to the HTTP body in chunks &mdash; Server</li>
      <li>Read data from the HTTP body in chunks &mdash; Mobile</li>
      <li>Deserialize in chunks &mdash; Mobile</li>
      <li>Write to SQLite in chunks &mdash; Mobile</li>
    </List>
  </section>

  <section class="flex flex-col gap-2">
    <Heading tag="h4">Database streaming</Heading>
    <Text
      >Reading from PostgreSQL in chunks was easy enough. Having just migrated to Kysely from TypeORM, we were already
      seeing massive improvements with regard to speed and memory usage in other parts of the application as we migrated
      queries to use the <Link href="https://kysely-org.github.io/kysely-apidoc/interfaces/Streamable.html" external>
        streaming
      </Link> interface (see <GithubReference number={16600} />, <GithubReference number={16666} />, <GithubReference
        number={16700}
      />, <GithubReference number={16706} />, etc.).</Text
    >
  </section>

  <section class="flex flex-col gap-2">
    <Text>Here is an example of what streaming looks like when querying albums:</Text>
    <CodeBlock
      code={`return this.db
  .selectFrom('album')
  .select([
    'album.id',
    'album.ownerId',
    // ...
  ])
  .where('album.ownerId', '=', userId)
  // send back a stream of results
  .stream();
}`}
    />
  </section>

  <Text>
    This enabled streaming from the database to the Node.js process, but the server still needed to send the data across
    the network in chunks. This was initially problematic as JSON is not a streamable format. We discussed a variety of
    protocols, but eventually decided to use the <Link href="https://jsonlines.org/" external>JSON Lines</Link> format for
    simplicity.
  </Text>

  <section class="flex flex-col gap-2">
    <Heading tag="h4">JSON Lines</Heading>
    <Text
      >JSON Lines is a convenient format for streaming JSON data over a network connection. Each line is a separate JSON
      object, making it easy to process the data incrementally.
    </Text>
  </section>

  <section class="flex flex-col gap-2">
    <Text>Here is what the serialization logic looks like:</Text>
    <CodeBlock
      code={`const send = (response: Writable, objects: unknown[]) => {
  for(const object of objects){
    response.write(JSON.stringify(object) + '\\n')
  }
};`}
    />
  </section>

  <Text
    >The <Code>Content-Type</Code> header just needs to be changed from <Code>application/json</Code> to <Code
      >application/jsonlines+json</Code
    >.</Text
  >

  <section class="flex flex-col gap-2">
    <Heading tag="h4">Mobile streaming</Heading>
    <Text
      >On the other side, the mobile app essentially does the opposite. It reads the data in chunks, concatenating the
      JSON objects as they arrive, making sure to only process complete lines.</Text
    >

    <CodeBlock
      code={`await for (final chunk in response.stream.transform(utf8.decoder)) {
  if (shouldAbort) {
    break;
  }

  previousChunk += chunk;
  final parts = previousChunk.toString().split('\\n');
  previousChunk = parts.removeLast();
  lines.addAll(parts);

  if (lines.length < batchSize) {
    continue;
  }

  await onData(_parseLines(lines), abort, reset);
  lines.clear();
}`}
      language={dart}
    />
  </section>

  <section class="flex flex-col gap-2">
    <Heading tag="h3" size="large">Resumable</Heading>
    <Text>
      Now that we had figured out how to end-to-end stream data to the mobile app, the next step was figuring out how to
      make the whole process <i>resumable</i>. If there was a network interruption, or the client disconnected part way
      through the sync, we wanted to be able to pick up where we left off, instead of having to start over from square
      one. This led us to the idea of <i>checkpoints</i> and <i>acknowledgements</i>. The basic idea was to keep track
      of the last, successfully received row, per table. The server would send an acknowledgement token with each row,
      and the mobile app would periodically send this token back, as a confirmation. If the connection was lost, the
      mobile app would initialize a new connection and the server would automatically pick up where it left off.
    </Text>
  </section>

  <section class="flex flex-col gap-2">
    <Text>There were some details that were important to get right as we were implementing this, such as:</Text>
    <List>
      <li><b>Determinism</b> &mdash; the query needed to be resumable in a predictable manner</li>
      <li>
        <b>Speed</b> &mdash; the query needed to have an index that would allow us to index into the result set right where
        we left off
      </li>
      <li>
        <b>Bulk updates</b> &mdash; the query needed to be able to handle batches of records getting updated in the same
        transaction
      </li>
    </List>
  </section>

  <Text>
    Initially we started using a simple <Code>updatedAt</Code> timestamp column, but that ended up being problematic if you
    had multiple records updated in the same millisecond. Eventually, we transitioned to <Code>UUIDv7</Code> IDs, which are
    inherently unique while also being time-based.
  </Text>

  <section class="flex flex-col gap-2">
    <Heading tag="h3" size="large">UUIDv7</Heading>
    <Text>
      Per the <Link
        href="https://www.ietf.org/archive/id/draft-peabody-dispatch-new-uuid-format-01.html#name-uuidv7-layout-and-bit-order"
        external>specification</Link
      >, the first 48 bits of the ID are a timestamp, with millisecond precision. This means that we can use the <Code
        >UUIDv7</Code
      >
      as a reliable, unique, and fast index for our queries. We can easily query for all records with an ID greater than
      the last acknowledged ID, and be guaranteed that we will get all records that were created or updated after that point
      in time.
    </Text>
  </section>

  <section class="flex flex-col gap-2">
    <Text>Here is what the final query looks like, using the <Code>UUIDv7</Code> ID as the checkpoint:</Text>
    <CodeBlock
      code={`return this.db
  .selectFrom('album')
  .select([
    'album.id',
    'album.ownerId',
    // ...
  ])
  .where('album.ownerId', '=', userId)
  .where('album.updateId', '<', checkpointId) // checkpoint
  .orderBy('album.updateId', 'asc')           // deterministic
  .stream();`}
    />
  </section>

  <section class="flex flex-col gap-2">
    <Heading tag="h3" size="large">Response format</Heading>
    <Text
      >It is worth talking, briefly, about the response format. Each JSON line uses the following format, with a type,
      acknowledgement token, and a data object:</Text
    >
    <CodeBlock
      code={`{
  "type": "AlbumV1",
  "ack": "0197b214-ba2c-7c71-89d1-4bbb56a51d06",
  "data": {
    "id": "<UUID>",
    // ...
    }
  }
}`}
      language={json}
    />
  </section>

  <Text
    >The <Code>ack</Code> token can be <Code>POST</Code>-ed back to the server, after the data has been persisted to
    SQLite, client-side. The <Code>type</Code> and <Code>data</Code> fields are versioned domain-transfer-objects, which
    enable the mobile app to safely deserialize the data.
  </Text>

  <section class="flex flex-col gap-2">
    <Heading tag="h3" size="large">Checkpoints</Heading>
    <Text>
      <!--  -->
      Acknowledgements are heavily connected to the idea of checkpoints, which are essentially an acknowledgement that is
      connected to a specific table. More specifically, a specific <i>query</i>. It turns out that, because of sharing,
      there are a few situations where we actually need to track the sync progress in two or more different ways for the
      same table, such as the <Code>asset</Code> table.
    </Text>
  </section>

  <CodeBlock
    code={`export class SessionSyncCheckpointTable {
  @ForeignKeyColumn(() => SessionTable, { onDelete: 'CASCADE', onUpdate: 'CASCADE', primary: true })
  sessionId!: string;

  @PrimaryColumn({ type: 'character varying' })
  type!: SyncEntityType;

  @CreateDateColumn()
  createdAt!: Generated<Timestamp>;

  @UpdateDateColumn()
  updatedAt!: Generated<Timestamp>;

  @Column()
  ack!: string;

  @UpdateIdColumn({ index: true })
  updateId!: Generated<string>;
}`}
  />

  <Text
    >As you can see a checkpoint is tied to a specific session and <Code>SyncEntityType</Code>. The <Code
      >SyncEntityType</Code
    > represents a specific database query. Examples include:</Text
  >

  <List>
    <li><Code>AuthUserV1</Code></li>
    <li><Code>UserV1</Code></li>
    <li><Code>UserDeleteV1</Code></li>
    <li><Code>AssetV1</Code></li>
    <li><Code>AssetDeleteV1</Code></li>
    <li><Code>AssetExifV1</Code></li>
    <li><Code>AlbumV1</Code></li>
    <li><Code>AlbumDeleteV1</Code></li>
    <li>etc.</li>
  </List>

  <section class="flex flex-col gap-2">
    <Heading tag="h3" size="large">Deletes</Heading>
    <Text>
      One thing that was a bit more annoying to manage was tracking deletes. Since the mobile app needs to know when to
      delete a record from its database, the server would need to hold on to deleted data for some period of time, in
      order to be able to send it to the client. We decided to implement this via database triggers.
    </Text>
  </section>

  <section class="flex flex-col gap-2">
    <Heading tag="h4">Triggers as Code</Heading>
    <Text>
      A trigger can run before or after a row or transaction updates or deletes a set of data. Previously, we had tried
      to stay away from using triggers, mostly because they can be hard to reason about, and are a real pain to track
      and test. However, internally, we developed <Link
        href="https://github.com/immich-app/immich/tree/main/server/src/sql-tools"
        external>some tooling around schema tracking</Link
      > that we extended to include triggers and functions, and this has made it much more manageable.
    </Text>
  </section>

  <section class="flex flex-col gap-2">
    <Text>Here are some common building blocks that we made:</Text>
    <CodeBlock
      code={`export const updated_at = registerFunction({
  name: 'updated_at',
  returnType: 'TRIGGER',
  language: 'PLPGSQL',
  body: \`
    DECLARE
        clock_timestamp TIMESTAMP := clock_timestamp();
    BEGIN
        new."updatedAt" = clock_timestamp;
        new."updateId" = immich_uuid_v7(clock_timestamp);
        return new;
    END;\`,
});

export const UpdatedAtTrigger = (name: string) =>
  BeforeUpdateTrigger({
    name,
    scope: 'row',
    function: updated_at,
  });`}
    />
  </section>

  <section class="flex flex-col gap-2">
    <Text>With those blocks, here is what it took to track deletes on the <Code>asset</Code> table.</Text>
    <CodeBlock
      code={`const asset_delete_audit = registerFunction({
  name: 'asset_delete_audit',
  returnType: 'TRIGGER',
  language: 'PLPGSQL',
  body: \`
    BEGIN
      INSERT INTO asset_audit ("assetId", "ownerId")
      SELECT "id", "ownerId"
      FROM OLD;
      RETURN NULL;
    END\`,
});

@Table('asset')
@UpdatedAtTrigger('asset_updatedAt')
@AfterDeleteTrigger({
  scope: 'statement',
  function: asset_delete_audit,
  referencingOldTableAs: 'old',
  when: 'pg_trigger_depth() = 0',
})
class AssetTable {
  @PrimaryGeneratedColumn()
  id!: Generated<string>;

  // ...
}`}
    />
  </section>

  <Text
    >With this tooling, which automatically generates migrations, tracks drift, and provides reusable building blocks
    for common database operations, we were able to streamline our development process regarding audit tables. Also, we
    were able to design a robust system to test these triggers and functions.</Text
  >

  <section class="flex flex-col gap-2">
    <Heading tag="h3" size="large">Testing</Heading>
    <Text>
      From the first discussion, we knew that testing would be crucial to the success of the new implementation. We
      especially wanted to validate that the same data would not be sent multiple times, that the sync was resumable,
      and that, with all the sharing rules, the right data was being sent to the right user.
    </Text>
  </section>

  <section class="flex flex-col gap-2">
    <Heading tag="h4">Medium tests</Heading>
    <Text>
      If you have never heard of medium tests, you have probably heard of integration tests. Medium tests are
      essentially integration tests, except that they aren't restricted to specific layers of the application. They are
      bigger than unit tests, but not as big as end-to-end tests. In our case, they spin up a real database, and execute
      real queries against it, and they run <i>super</i> fast.
    </Text>
  </section>

  <Text
    >With a framework for executing real queries against a real database, we are able to describe expected sync
    situations and validate that they are working properly. Since the test uses a real database and queries, we have
    high confidence that the code is working as expected.</Text
  >

  <section class="flex flex-col gap-2">
    <Text>Here is a sample test that checks that a deleted asset is detected and sent</Text>
    <CodeBlock
      code={`it('should detect and sync a deleted asset', async () => {
  const { auth, ctx } = await setup();
  const assetRepo = ctx.get(AssetRepository);
  const { asset } = await ctx.newAsset({ ownerId: auth.user.id });
  await assetRepo.remove(asset);

  const response = await ctx.syncStream(auth, [SyncRequestType.AssetsV1]);
  expect(response).toEqual([
    {
      ack: expect.any(String),
      data: {
        assetId: asset.id,
      },
      type: 'AssetDeleteV1',
    },
    expect.objectContaining({ type: SyncEntityType.SyncCompleteV1 }),
  ]);

  await ctx.syncAckAll(auth, response);
  await ctx.assertSyncIsComplete(auth, [SyncRequestType.AssetsV1]);
});`}
    />
  </section>

  <section class="flex flex-col gap-2">
    <Text>Currently, we have 185 medium tests, that run in about 10 seconds.</Text>
    <img src={mediumTests} alt="185 medium tests running in 11 seconds" class="rounded-2xl" />
  </section>

  <Text
    >We have tests for various scenarios, including asset creates, updates, and deletes, assets being added and removed
    from albums, albums being created, updated, and deleted, albums being shared and unshared with users, users being
    created, updated, and deleted, exif being updated, partner sharing being enabled and disabled, and many, many more.</Text
  >

  <Text
    >We also have mechanisms built into the process to allow the server to communicate to the client that it needs to do
    a full sync, instead of an incremental sync. Similarly, the client can tell the server when it wants reset all
    checkpoints and start from scratch. This has been super useful for the mobile developers as they have been testing
    and troubleshooting.</Text
  >

  <section class="flex flex-col gap-2">
    <Heading tag="h3" size="large">Conclusion</Heading>
    <Text>
      In short, the team has been working hard for most of this year, in order to improve the sync process and make it
      more efficient. We believe the new process has achieved all of our goals. It is <i>resumable</i>,
      <i>incremental</i>, and <i>performant</i>. The new process takes less time and uses less memory. It has involved a
      lot of work, but we believe the results have been worth it. Moving forward, we plan to continue to expand the
      process to more tables and objects, and add tests for any issues or bugs that we discover along the way.
    </Text>
  </section>
</BlogPage>
